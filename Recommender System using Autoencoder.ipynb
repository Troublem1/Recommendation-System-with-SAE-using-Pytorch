{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# *Recommender System Model with Stacked Autoencoder*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Intuition**: We will build a Stacked Autoencoder to generate predictions of viewer ratings for our Recommender System using Pytorch. To learn more about Stacked (Denoising) Autoencoders, check out the following paper: http://www.jmlr.org/papers/volume11/vincent10a/vincent10a.pdf.\n",
    "\n",
    "**Dataset Source**: https://grouplens.org/datasets/movielens/100k/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing libraries and packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.parallel\n",
    "import torch.optim as optim\n",
    "import torch.utils.data\n",
    "from torch.autograd import Variable\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing the Training Set & Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>1.1</th>\n",
       "      <th>5</th>\n",
       "      <th>874965758</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>876893171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>878542960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>876893119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>889751712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>875071561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79994</th>\n",
       "      <td>943</td>\n",
       "      <td>1067</td>\n",
       "      <td>2</td>\n",
       "      <td>875501756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79995</th>\n",
       "      <td>943</td>\n",
       "      <td>1074</td>\n",
       "      <td>4</td>\n",
       "      <td>888640250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79996</th>\n",
       "      <td>943</td>\n",
       "      <td>1188</td>\n",
       "      <td>3</td>\n",
       "      <td>888640250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79997</th>\n",
       "      <td>943</td>\n",
       "      <td>1228</td>\n",
       "      <td>3</td>\n",
       "      <td>888640275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79998</th>\n",
       "      <td>943</td>\n",
       "      <td>1330</td>\n",
       "      <td>3</td>\n",
       "      <td>888692465</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>79999 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         1   1.1  5  874965758\n",
       "0        1     2  3  876893171\n",
       "1        1     3  4  878542960\n",
       "2        1     4  3  876893119\n",
       "3        1     5  3  889751712\n",
       "4        1     7  4  875071561\n",
       "...    ...   ... ..        ...\n",
       "79994  943  1067  2  875501756\n",
       "79995  943  1074  4  888640250\n",
       "79996  943  1188  3  888640250\n",
       "79997  943  1228  3  888640275\n",
       "79998  943  1330  3  888692465\n",
       "\n",
       "[79999 rows x 4 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_set = pd.read_csv('ml-100k/u1.base', delimiter = '\\t')\n",
    "training_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>6</th>\n",
       "      <th>5</th>\n",
       "      <th>887431973</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>875693118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>5</td>\n",
       "      <td>878542960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>5</td>\n",
       "      <td>874965706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>3</td>\n",
       "      <td>875073198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>4</td>\n",
       "      <td>887431883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19994</th>\n",
       "      <td>458</td>\n",
       "      <td>648</td>\n",
       "      <td>4</td>\n",
       "      <td>886395899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19995</th>\n",
       "      <td>458</td>\n",
       "      <td>1101</td>\n",
       "      <td>4</td>\n",
       "      <td>886397931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19996</th>\n",
       "      <td>459</td>\n",
       "      <td>934</td>\n",
       "      <td>3</td>\n",
       "      <td>879563639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19997</th>\n",
       "      <td>460</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>882912371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19998</th>\n",
       "      <td>462</td>\n",
       "      <td>682</td>\n",
       "      <td>5</td>\n",
       "      <td>886365231</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>19999 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         1     6  5  887431973\n",
       "0        1    10  3  875693118\n",
       "1        1    12  5  878542960\n",
       "2        1    14  5  874965706\n",
       "3        1    17  3  875073198\n",
       "4        1    20  4  887431883\n",
       "...    ...   ... ..        ...\n",
       "19994  458   648  4  886395899\n",
       "19995  458  1101  4  886397931\n",
       "19996  459   934  3  879563639\n",
       "19997  460    10  3  882912371\n",
       "19998  462   682  5  886365231\n",
       "\n",
       "[19999 rows x 4 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_set = pd.read_csv('ml-100k/u1.test', delimiter = '\\t')\n",
    "test_set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transforming the Training Set & Test Set into Arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[        1,         2,         3, 876893171],\n",
       "       [        1,         3,         4, 878542960],\n",
       "       [        1,         4,         3, 876893119],\n",
       "       ...,\n",
       "       [      943,      1188,         3, 888640250],\n",
       "       [      943,      1228,         3, 888640275],\n",
       "       [      943,      1330,         3, 888692465]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_set_copy = training_set.copy()\n",
    "training_set = np.array(training_set, dtype = 'int')\n",
    "training_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[        1,        10,         3, 875693118],\n",
       "       [        1,        12,         5, 878542960],\n",
       "       [        1,        14,         5, 874965706],\n",
       "       ...,\n",
       "       [      459,       934,         3, 879563639],\n",
       "       [      460,        10,         3, 882912371],\n",
       "       [      462,       682,         5, 886365231]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_set_copy = test_set.copy()\n",
    "test_set = np.array(test_set, dtype = 'int')\n",
    "test_set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting the number of users and movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of users = 943 \n",
      "Total number of movies = 1682\n"
     ]
    }
   ],
   "source": [
    "nb_users = int(max(max(training_set[:,0]), max(test_set[:,0])))\n",
    "nb_movies = int(max(max(training_set[:,1]), max(test_set[:,1])))\n",
    "print('Total number of users = %s' % nb_users, '\\nTotal number of movies = %s' % nb_movies)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Converting the data into an array with users in lines and movies in columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert(data):\n",
    "    new_data = []\n",
    "    for id_users in range(1, nb_users + 1):\n",
    "        id_movies = data[:,1][data[:,0] == id_users]\n",
    "        id_ratings = data[:,2][data[:,0] == id_users]\n",
    "        ratings = np.zeros(nb_movies)\n",
    "        ratings[id_movies - 1] = id_ratings\n",
    "        new_data.append(list(ratings))\n",
    "    return new_data\n",
    "training_set = convert(training_set)\n",
    "test_set = convert(test_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Converting the Training Set & Test Set into PyTorch Tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set = torch.FloatTensor(training_set)\n",
    "test_set = torch.FloatTensor(test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 3., 4.,  ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_set[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0.,  ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_set[:1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Structuring the Stacked Autoencoder class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SAE(nn.Module):\n",
    "    def __init__(self, ):\n",
    "        super(SAE, self).__init__()\n",
    "        self.fc1 = nn.Linear(nb_movies, 20)\n",
    "        self.fc2 = nn.Linear(20, 10)\n",
    "        self.fc3 = nn.Linear(10, 20)\n",
    "        self.fc4 = nn.Linear(20, nb_movies)\n",
    "        self.activation = nn.Sigmoid()\n",
    "    def forward(self, x):\n",
    "        x = self.activation(self.fc1(x))\n",
    "        x = self.activation(self.fc2(x))\n",
    "        x = self.activation(self.fc3(x))\n",
    "        x = self.fc4(x)\n",
    "        return x\n",
    "sae = SAE()\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.RMSprop(sae.parameters(), lr = 0.01, weight_decay = 0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the Stacked Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 & Training Loss: tensor(1.7715)\n",
      "Epoch: 2 & Training Loss: tensor(1.0968)\n",
      "Epoch: 3 & Training Loss: tensor(1.0534)\n",
      "Epoch: 4 & Training Loss: tensor(1.0382)\n",
      "Epoch: 5 & Training Loss: tensor(1.0309)\n",
      "Epoch: 6 & Training Loss: tensor(1.0266)\n",
      "Epoch: 7 & Training Loss: tensor(1.0238)\n",
      "Epoch: 8 & Training Loss: tensor(1.0219)\n",
      "Epoch: 9 & Training Loss: tensor(1.0207)\n",
      "Epoch: 10 & Training Loss: tensor(1.0195)\n",
      "Epoch: 11 & Training Loss: tensor(1.0187)\n",
      "Epoch: 12 & Training Loss: tensor(1.0187)\n",
      "Epoch: 13 & Training Loss: tensor(1.0178)\n",
      "Epoch: 14 & Training Loss: tensor(1.0175)\n",
      "Epoch: 15 & Training Loss: tensor(1.0173)\n",
      "Epoch: 16 & Training Loss: tensor(1.0170)\n",
      "Epoch: 17 & Training Loss: tensor(1.0167)\n",
      "Epoch: 18 & Training Loss: tensor(1.0164)\n",
      "Epoch: 19 & Training Loss: tensor(1.0164)\n",
      "Epoch: 20 & Training Loss: tensor(1.0161)\n",
      "Epoch: 21 & Training Loss: tensor(1.0160)\n",
      "Epoch: 22 & Training Loss: tensor(1.0159)\n",
      "Epoch: 23 & Training Loss: tensor(1.0158)\n",
      "Epoch: 24 & Training Loss: tensor(1.0159)\n",
      "Epoch: 25 & Training Loss: tensor(1.0156)\n",
      "Epoch: 26 & Training Loss: tensor(1.0154)\n",
      "Epoch: 27 & Training Loss: tensor(1.0152)\n",
      "Epoch: 28 & Training Loss: tensor(1.0153)\n",
      "Epoch: 29 & Training Loss: tensor(1.0127)\n",
      "Epoch: 30 & Training Loss: tensor(1.0120)\n",
      "Epoch: 31 & Training Loss: tensor(1.0098)\n",
      "Epoch: 32 & Training Loss: tensor(1.0099)\n",
      "Epoch: 33 & Training Loss: tensor(1.0054)\n",
      "Epoch: 34 & Training Loss: tensor(1.0059)\n",
      "Epoch: 35 & Training Loss: tensor(1.0020)\n",
      "Epoch: 36 & Training Loss: tensor(0.9995)\n",
      "Epoch: 37 & Training Loss: tensor(0.9974)\n",
      "Epoch: 38 & Training Loss: tensor(0.9958)\n",
      "Epoch: 39 & Training Loss: tensor(0.9941)\n",
      "Epoch: 40 & Training Loss: tensor(0.9931)\n",
      "Epoch: 41 & Training Loss: tensor(0.9911)\n",
      "Epoch: 42 & Training Loss: tensor(0.9889)\n",
      "Epoch: 43 & Training Loss: tensor(0.9866)\n",
      "Epoch: 44 & Training Loss: tensor(0.9908)\n",
      "Epoch: 45 & Training Loss: tensor(0.9874)\n",
      "Epoch: 46 & Training Loss: tensor(0.9869)\n",
      "Epoch: 47 & Training Loss: tensor(0.9817)\n",
      "Epoch: 48 & Training Loss: tensor(0.9824)\n",
      "Epoch: 49 & Training Loss: tensor(0.9774)\n",
      "Epoch: 50 & Training Loss: tensor(0.9796)\n",
      "Epoch: 51 & Training Loss: tensor(0.9744)\n",
      "Epoch: 52 & Training Loss: tensor(0.9730)\n",
      "Epoch: 53 & Training Loss: tensor(0.9715)\n",
      "Epoch: 54 & Training Loss: tensor(0.9756)\n",
      "Epoch: 55 & Training Loss: tensor(0.9684)\n",
      "Epoch: 56 & Training Loss: tensor(0.9722)\n",
      "Epoch: 57 & Training Loss: tensor(0.9689)\n",
      "Epoch: 58 & Training Loss: tensor(0.9704)\n",
      "Epoch: 59 & Training Loss: tensor(0.9659)\n",
      "Epoch: 60 & Training Loss: tensor(0.9639)\n",
      "Epoch: 61 & Training Loss: tensor(0.9618)\n",
      "Epoch: 62 & Training Loss: tensor(0.9609)\n",
      "Epoch: 63 & Training Loss: tensor(0.9596)\n",
      "Epoch: 64 & Training Loss: tensor(0.9562)\n",
      "Epoch: 65 & Training Loss: tensor(0.9531)\n",
      "Epoch: 66 & Training Loss: tensor(0.9537)\n",
      "Epoch: 67 & Training Loss: tensor(0.9549)\n",
      "Epoch: 68 & Training Loss: tensor(0.9523)\n",
      "Epoch: 69 & Training Loss: tensor(0.9502)\n",
      "Epoch: 70 & Training Loss: tensor(0.9555)\n",
      "Epoch: 71 & Training Loss: tensor(0.9510)\n",
      "Epoch: 72 & Training Loss: tensor(0.9501)\n",
      "Epoch: 73 & Training Loss: tensor(0.9488)\n",
      "Epoch: 74 & Training Loss: tensor(0.9478)\n",
      "Epoch: 75 & Training Loss: tensor(0.9459)\n",
      "Epoch: 76 & Training Loss: tensor(0.9465)\n",
      "Epoch: 77 & Training Loss: tensor(0.9442)\n",
      "Epoch: 78 & Training Loss: tensor(0.9453)\n",
      "Epoch: 79 & Training Loss: tensor(0.9434)\n",
      "Epoch: 80 & Training Loss: tensor(0.9438)\n",
      "Epoch: 81 & Training Loss: tensor(0.9413)\n",
      "Epoch: 82 & Training Loss: tensor(0.9427)\n",
      "Epoch: 83 & Training Loss: tensor(0.9402)\n",
      "Epoch: 84 & Training Loss: tensor(0.9410)\n",
      "Epoch: 85 & Training Loss: tensor(0.9390)\n",
      "Epoch: 86 & Training Loss: tensor(0.9398)\n",
      "Epoch: 87 & Training Loss: tensor(0.9370)\n",
      "Epoch: 88 & Training Loss: tensor(0.9386)\n",
      "Epoch: 89 & Training Loss: tensor(0.9357)\n",
      "Epoch: 90 & Training Loss: tensor(0.9374)\n",
      "Epoch: 91 & Training Loss: tensor(0.9354)\n",
      "Epoch: 92 & Training Loss: tensor(0.9370)\n",
      "Epoch: 93 & Training Loss: tensor(0.9350)\n",
      "Epoch: 94 & Training Loss: tensor(0.9363)\n",
      "Epoch: 95 & Training Loss: tensor(0.9344)\n",
      "Epoch: 96 & Training Loss: tensor(0.9354)\n",
      "Epoch: 97 & Training Loss: tensor(0.9335)\n",
      "Epoch: 98 & Training Loss: tensor(0.9351)\n",
      "Epoch: 99 & Training Loss: tensor(0.9325)\n",
      "Epoch: 100 & Training Loss: tensor(0.9338)\n",
      "Epoch: 101 & Training Loss: tensor(0.9321)\n",
      "Epoch: 102 & Training Loss: tensor(0.9342)\n",
      "Epoch: 103 & Training Loss: tensor(0.9315)\n",
      "Epoch: 104 & Training Loss: tensor(0.9332)\n",
      "Epoch: 105 & Training Loss: tensor(0.9309)\n",
      "Epoch: 106 & Training Loss: tensor(0.9324)\n",
      "Epoch: 107 & Training Loss: tensor(0.9304)\n",
      "Epoch: 108 & Training Loss: tensor(0.9319)\n",
      "Epoch: 109 & Training Loss: tensor(0.9298)\n",
      "Epoch: 110 & Training Loss: tensor(0.9310)\n",
      "Epoch: 111 & Training Loss: tensor(0.9298)\n",
      "Epoch: 112 & Training Loss: tensor(0.9309)\n",
      "Epoch: 113 & Training Loss: tensor(0.9291)\n",
      "Epoch: 114 & Training Loss: tensor(0.9302)\n",
      "Epoch: 115 & Training Loss: tensor(0.9292)\n",
      "Epoch: 116 & Training Loss: tensor(0.9298)\n",
      "Epoch: 117 & Training Loss: tensor(0.9282)\n",
      "Epoch: 118 & Training Loss: tensor(0.9293)\n",
      "Epoch: 119 & Training Loss: tensor(0.9278)\n",
      "Epoch: 120 & Training Loss: tensor(0.9288)\n",
      "Epoch: 121 & Training Loss: tensor(0.9270)\n",
      "Epoch: 122 & Training Loss: tensor(0.9283)\n",
      "Epoch: 123 & Training Loss: tensor(0.9268)\n",
      "Epoch: 124 & Training Loss: tensor(0.9277)\n",
      "Epoch: 125 & Training Loss: tensor(0.9263)\n",
      "Epoch: 126 & Training Loss: tensor(0.9272)\n",
      "Epoch: 127 & Training Loss: tensor(0.9259)\n",
      "Epoch: 128 & Training Loss: tensor(0.9266)\n",
      "Epoch: 129 & Training Loss: tensor(0.9251)\n",
      "Epoch: 130 & Training Loss: tensor(0.9261)\n",
      "Epoch: 131 & Training Loss: tensor(0.9247)\n",
      "Epoch: 132 & Training Loss: tensor(0.9258)\n",
      "Epoch: 133 & Training Loss: tensor(0.9243)\n",
      "Epoch: 134 & Training Loss: tensor(0.9248)\n",
      "Epoch: 135 & Training Loss: tensor(0.9237)\n",
      "Epoch: 136 & Training Loss: tensor(0.9248)\n",
      "Epoch: 137 & Training Loss: tensor(0.9234)\n",
      "Epoch: 138 & Training Loss: tensor(0.9241)\n",
      "Epoch: 139 & Training Loss: tensor(0.9227)\n",
      "Epoch: 140 & Training Loss: tensor(0.9236)\n",
      "Epoch: 141 & Training Loss: tensor(0.9222)\n",
      "Epoch: 142 & Training Loss: tensor(0.9230)\n",
      "Epoch: 143 & Training Loss: tensor(0.9221)\n",
      "Epoch: 144 & Training Loss: tensor(0.9230)\n",
      "Epoch: 145 & Training Loss: tensor(0.9216)\n",
      "Epoch: 146 & Training Loss: tensor(0.9222)\n",
      "Epoch: 147 & Training Loss: tensor(0.9210)\n",
      "Epoch: 148 & Training Loss: tensor(0.9216)\n",
      "Epoch: 149 & Training Loss: tensor(0.9208)\n",
      "Epoch: 150 & Training Loss: tensor(0.9215)\n",
      "Epoch: 151 & Training Loss: tensor(0.9203)\n",
      "Epoch: 152 & Training Loss: tensor(0.9210)\n",
      "Epoch: 153 & Training Loss: tensor(0.9199)\n",
      "Epoch: 154 & Training Loss: tensor(0.9206)\n",
      "Epoch: 155 & Training Loss: tensor(0.9195)\n",
      "Epoch: 156 & Training Loss: tensor(0.9204)\n",
      "Epoch: 157 & Training Loss: tensor(0.9190)\n",
      "Epoch: 158 & Training Loss: tensor(0.9199)\n",
      "Epoch: 159 & Training Loss: tensor(0.9190)\n",
      "Epoch: 160 & Training Loss: tensor(0.9195)\n",
      "Epoch: 161 & Training Loss: tensor(0.9182)\n",
      "Epoch: 162 & Training Loss: tensor(0.9191)\n",
      "Epoch: 163 & Training Loss: tensor(0.9179)\n",
      "Epoch: 164 & Training Loss: tensor(0.9191)\n",
      "Epoch: 165 & Training Loss: tensor(0.9176)\n",
      "Epoch: 166 & Training Loss: tensor(0.9184)\n",
      "Epoch: 167 & Training Loss: tensor(0.9173)\n",
      "Epoch: 168 & Training Loss: tensor(0.9184)\n",
      "Epoch: 169 & Training Loss: tensor(0.9169)\n",
      "Epoch: 170 & Training Loss: tensor(0.9181)\n",
      "Epoch: 171 & Training Loss: tensor(0.9166)\n",
      "Epoch: 172 & Training Loss: tensor(0.9175)\n",
      "Epoch: 173 & Training Loss: tensor(0.9163)\n",
      "Epoch: 174 & Training Loss: tensor(0.9172)\n",
      "Epoch: 175 & Training Loss: tensor(0.9162)\n",
      "Epoch: 176 & Training Loss: tensor(0.9171)\n",
      "Epoch: 177 & Training Loss: tensor(0.9158)\n",
      "Epoch: 178 & Training Loss: tensor(0.9167)\n",
      "Epoch: 179 & Training Loss: tensor(0.9156)\n",
      "Epoch: 180 & Training Loss: tensor(0.9165)\n",
      "Epoch: 181 & Training Loss: tensor(0.9154)\n",
      "Epoch: 182 & Training Loss: tensor(0.9161)\n",
      "Epoch: 183 & Training Loss: tensor(0.9150)\n",
      "Epoch: 184 & Training Loss: tensor(0.9155)\n",
      "Epoch: 185 & Training Loss: tensor(0.9146)\n",
      "Epoch: 186 & Training Loss: tensor(0.9155)\n",
      "Epoch: 187 & Training Loss: tensor(0.9148)\n",
      "Epoch: 188 & Training Loss: tensor(0.9152)\n",
      "Epoch: 189 & Training Loss: tensor(0.9145)\n",
      "Epoch: 190 & Training Loss: tensor(0.9152)\n",
      "Epoch: 191 & Training Loss: tensor(0.9142)\n",
      "Epoch: 192 & Training Loss: tensor(0.9147)\n",
      "Epoch: 193 & Training Loss: tensor(0.9139)\n",
      "Epoch: 194 & Training Loss: tensor(0.9146)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 195 & Training Loss: tensor(0.9139)\n",
      "Epoch: 196 & Training Loss: tensor(0.9142)\n",
      "Epoch: 197 & Training Loss: tensor(0.9136)\n",
      "Epoch: 198 & Training Loss: tensor(0.9141)\n",
      "Epoch: 199 & Training Loss: tensor(0.9133)\n",
      "Epoch: 200 & Training Loss: tensor(0.9136)\n"
     ]
    }
   ],
   "source": [
    "nb_epoch = 200\n",
    "for epoch in range(1, nb_epoch + 1):\n",
    "    train_loss = 0\n",
    "    s = 0.\n",
    "    for id_user in range(nb_users):\n",
    "        input = Variable(training_set[id_user]).unsqueeze(0)\n",
    "        target = input.clone()\n",
    "        if torch.sum(target.data > 0) > 0:\n",
    "            output = sae(input)\n",
    "            target.require_grad = False\n",
    "            output[target == 0] = 0\n",
    "            loss = criterion(output, target)\n",
    "            mean_corrector = nb_movies/float(torch.sum(target.data > 0) + 1e-10)\n",
    "            loss.backward()\n",
    "            train_loss += np.sqrt(loss.data*mean_corrector)\n",
    "            s += 1.\n",
    "            optimizer.step()\n",
    "    print('Epoch: '+str(epoch)+' & Training Loss: '+str(train_loss/s))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing the Stacked Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: tensor(0.9502)\n"
     ]
    }
   ],
   "source": [
    "test_loss = 0\n",
    "s = 0.\n",
    "for id_user in range(nb_users):\n",
    "    input = Variable(training_set[id_user]).unsqueeze(0)\n",
    "    target=Variable(test_set[id_user]).unsqueeze(0)\n",
    "    if torch.sum(target.data > 0) > 0:\n",
    "        output = sae(input)\n",
    "        target.require_grad = False\n",
    "        output[target == 0] = 0\n",
    "        loss = criterion(output, target)\n",
    "        mean_corrector = nb_movies/float(torch.sum(target.data > 0) + 1e-10)\n",
    "        test_loss += np.sqrt(loss.data * mean_corrector)\n",
    "        s += 1.\n",
    "print('Test Loss: '+str(test_loss/s))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting the title of the Movies from the Movies dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Toy Story (1995)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GoldenEye (1995)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Four Rooms (1995)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Get Shorty (1995)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Copycat (1995)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1677</th>\n",
       "      <td>Mat' i syn (1997)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1678</th>\n",
       "      <td>B. Monkey (1998)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1679</th>\n",
       "      <td>Sliding Doors (1998)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1680</th>\n",
       "      <td>You So Crazy (1994)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1681</th>\n",
       "      <td>Scream of Stone (Schrei aus Stein) (1991)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1682 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              1\n",
       "0                              Toy Story (1995)\n",
       "1                              GoldenEye (1995)\n",
       "2                             Four Rooms (1995)\n",
       "3                             Get Shorty (1995)\n",
       "4                                Copycat (1995)\n",
       "...                                         ...\n",
       "1677                          Mat' i syn (1997)\n",
       "1678                           B. Monkey (1998)\n",
       "1679                       Sliding Doors (1998)\n",
       "1680                        You So Crazy (1994)\n",
       "1681  Scream of Stone (Schrei aus Stein) (1991)\n",
       "\n",
       "[1682 rows x 1 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movies = pd.read_csv('ml-100k/u.item', sep = '|', engine = 'python', encoding = 'latin-1', header = None)\n",
    "movie_title = movies.iloc[:nb_movies, 1:2]\n",
    "movie_title"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choosing a User by the Test Set and taking the whole list of Movies of that User"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_id = 101\n",
    "user_rating = training_set.data.numpy()[user_id - 1, :].reshape(-1,1)\n",
    "user_target = test_set.data.numpy()[user_id, :].reshape(-1,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Making the Predictions using the Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2.8014321],\n",
       "       [2.2636726],\n",
       "       [1.7945926],\n",
       "       ...,\n",
       "       [1.4948449],\n",
       "       [2.4509208],\n",
       "       [2.236212 ]], dtype=float32)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_input = Variable(training_set[user_id]).unsqueeze(0)\n",
    "predicted = sae(user_input)\n",
    "predicted = predicted.data.numpy().reshape(-1,1)\n",
    "predicted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combining all the info into one dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Movie</th>\n",
       "      <th>Target Rating</th>\n",
       "      <th>Predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Copycat (1995)</td>\n",
       "      <td>3</td>\n",
       "      <td>2.27144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ed Wood (1994)</td>\n",
       "      <td>2</td>\n",
       "      <td>2.69804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Star Wars (1977)</td>\n",
       "      <td>4</td>\n",
       "      <td>3.66983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Stargate (1994)</td>\n",
       "      <td>3</td>\n",
       "      <td>2.41681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>While You Were Sleeping (1995)</td>\n",
       "      <td>3</td>\n",
       "      <td>2.6145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Chain Reaction (1996)</td>\n",
       "      <td>2</td>\n",
       "      <td>1.9055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>Turbulence (1997)</td>\n",
       "      <td>1</td>\n",
       "      <td>1.34292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>Fire Down Below (1997)</td>\n",
       "      <td>2</td>\n",
       "      <td>1.37296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>Beverly Hillbillies, The (1993)</td>\n",
       "      <td>1</td>\n",
       "      <td>1.62214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>Cutthroat Island (1995)</td>\n",
       "      <td>2</td>\n",
       "      <td>1.78037</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>104 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                               Movie Target Rating Predicted\n",
       "0                     Copycat (1995)             3   2.27144\n",
       "1                     Ed Wood (1994)             2   2.69804\n",
       "2                   Star Wars (1977)             4   3.66983\n",
       "3                    Stargate (1994)             3   2.41681\n",
       "4     While You Were Sleeping (1995)             3    2.6145\n",
       "..                               ...           ...       ...\n",
       "99             Chain Reaction (1996)             2    1.9055\n",
       "100                Turbulence (1997)             1   1.34292\n",
       "101           Fire Down Below (1997)             2   1.37296\n",
       "102  Beverly Hillbillies, The (1993)             1   1.62214\n",
       "103          Cutthroat Island (1995)             2   1.78037\n",
       "\n",
       "[104 rows x 3 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_array = np.hstack([movie_title, user_target, predicted])\n",
    "result_array = result_array[result_array[:, 1] > 0]\n",
    "result_df = pd.DataFrame(data=result_array, columns=['Movie', 'Target Rating', 'Predicted'])\n",
    "result_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exporting the Results as a CSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df.to_csv('Generated ratings vs OG ratings.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*The code (In [17]) was ran to check the predicted ratings compared to the real ratings (target) obtained from test dataset.\n",
    "The resulting Dataframe has the movie name, the target rate (obtained from the Test Dataset) and the predicted  rating. The resulting array was filtered to show only the movies that has been predicted, that is, the movies that have the rating > 0 in the Test Set. The results can be also be viewed in the exported CSV file.*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
